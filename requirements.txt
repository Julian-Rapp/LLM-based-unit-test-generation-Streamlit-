
REQUIREMENTS:
- Generate a single test file targeting the code above.
- Include tests for edge cases and obvious failure paths.
- If the public API is unclear, make a reasonable assumption and justify it briefly in test names/comments (not outside the code block).
- Do not attempt any network calls or disk writes in tests.
- Prefer deterministic tests.
"""

def extract_filename_from_header(text: str, language: str):
    # Look for "# FILE: ..." or "// FILE: ..."
    patterns = [
        r"^#\s*FILE:\s*(?P<fname>.+)$",
        r"^//\s*FILE:\s*(?P<fname>.+)$",
    ]
    for pat in patterns:
        m = re.search(pat, text, re.MULTILINE)
        if m:
            candidate = m.group("fname").strip()
            # Sanitize
            candidate = candidate.replace("\\", "/").split("/")[-1]
            if len(candidate) > 0:
                return candidate
    return None

def get_default_filename(language: str, framework: str) -> str:
    return DEFAULT_TEST_FILENAME.get((language, framework), "generated_tests.txt")

def call_openai(model: str, system_prompt: str, user_prompt: str, temperature: float = 0.2, max_tokens: int = 1800):
    """
    Uses the OpenAI Chat Completions API via 'openai' >= 1.x client.
    Streams the response chunks and yields content for Streamlit's write_stream.
    """
    try:
        from openai import OpenAI
    except Exception as e:
        raise RuntimeError(
            "OpenAI package not found. Ensure 'openai' is in requirements.txt.\n" + str(e)
        )
    api_key = os.environ.get("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", "")
    if not api_key:
        raise RuntimeError("No OpenAI API key found. Set it as a Streamlit secret or environment variable 'OPENAI_API_KEY'.")

    client = OpenAI(api_key=api_key)

    # Stream response
    stream = client.chat.completions.create(
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )

    for chunk in stream:
        delta = chunk.choices[0].delta.content or ""
        if delta:
            yield delta

def strip_code_fence(text: str) -> str:
    """
    Remove a single outer triple-backtick fence if present and return the inside.
    """
    fence = re.compile(r"^\s*```[\w-]*\s*\n(.*)\n```s*\s*$", re.DOTALL)
    m = fence.match(text)
    return m.group(1) if m else text

# --------- SIDEBAR ---------
with st.sidebar:
    st.header("Settings")
    language = st.selectbox("Language", list(LANG_FRAMEWORKS.keys()), index=0)
    framework = st.selectbox("Test framework", LANG_FRAMEWORKS[language], index=0)

    st.markdown("**LLM**")
    model = st.selectbox(
        "OpenAI model",
        # Keep choices conservative; adjust if you have access to larger models
        options=["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini"],
        index=0
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.2, 0.05)

    st.markdown("**Options**")
    property_tests = st.checkbox("Try property-based tests (if supported)", value=True)
    mocks_ok = st.checkbox("Allow mocks/stubs for time/random/I/O", value=True)

    st.divider()
    st.info(
        "Set your OpenAI API key as a Streamlit secret (`OPENAI_API_KEY`) or as an environment variable. "
        "The app generates tests but does not execute your code."
    )

# --------- MAIN INPUT ---------
col_left, col_right = st.columns([3, 2], gap="large")

with col_left:
    st.subheader("1) Paste your source code")
    code = st.text_area(
        f"{language} source code",
        value=EXAMPLES[language],
        height=300,
        placeholder=f"Paste your {language} code here...",
        label_visibility="visible",
    )
    use_example = st.button("Use example", type="secondary", help="Load a minimal example for this language.")
    if use_example:
        st.session_state["code"] = EXAMPLES[language]
        code = EXAMPLES[language]

with col_right:
    st.subheader("2) Generate tests")
    generate = st.button("Generate Unit Tests", type="primary")
    st.caption("This will call the OpenAI API and stream the result below.")

st.divider()
st.subheader("Output")

# --------- GENERATION ---------
if generate:
    if not code.strip():
        st.error("Please paste some code first.")
    else:
        funcs, classes = ([], [])
        if language == "Python":
            funcs, classes = parse_python_symbols(code)

        sys_prompt = build_system_prompt(language, framework, property_tests, mocks_ok)
        user_prompt = build_user_prompt(code, language, framework, funcs, classes)

        try:
            st.write("Generatingâ€¦")
            streamed_text = st.write_stream(
                call_openai(
                    model=model,
                    system_prompt=sys_prompt,
                    user_prompt=user_prompt,
                    temperature=temperature,
                )
            )
            # Persist in session state for download
            st.session_state["raw_output"] = streamed_text
        except Exception as e:
            st.error(f"Generation failed: {e}")

# --------- POST-PROCESSING ---------
raw_output = st.session_state.get("raw_output")
if raw_output:
    # Extract code block content if the model returned fenced code
    code_only = raw_output

    # If the model wrapped output in triple backticks, strip them
    if "```" in raw_output:
        # Grab the first code fence content
        m = re.search(r"```[\w-]*\s*(.*?)```", raw_output, flags=re.DOTALL)
        if m:
            code_only = m.group(1).strip()

    # Detect filename from header
    detected_filename = extract_filename_from_header(code_only, language)
    if not detected_filename:
        detected_filename = get_default_filename(language, framework)

    st.success(f"Suggested filename: `{detected_filename}`")
    st.code(code_only, language="python" if language == "Python" else "javascript" if language == "JavaScript" else "java" if language == "Java" else "go")

    # Download
    st.download_button(
        "Download test file",
        data=code_only.encode("utf-8"),
        file_name=detected_filename,
        mime="text/plain",
        type="primary",
        help="Save the generated test to your machine.",
    )

    # Minimal guidance
    with st.expander("How to run the tests (quick notes)"):
        if language == "Python" and framework == "pytest":
            st.markdown("- Install pytest: `pip install pytest hypothesis` (if using property tests)\n- Run: `pytest -q`")
        elif language == "Python" and framework == "unittest":
            st.markdown("- Run: `python -m unittest -v`  (add `hypothesis` if property tests were generated).")
        elif language == "JavaScript":
            st.markdown("- Install your framework (e.g., `npm i -D jest` or `npm i -D mocha chai` and `npm i -D fast-check` if property tests were generated).")
        elif language == "Java":
            st.markdown("- Ensure JUnit 5 on the classpath (Maven/Gradle).")
        elif language == "Go":
            st.markdown("- Run: `go test ./...`")

# --------- FOOTER ---------
st.divider()
st.caption(
    "Disclaimer: LLM-generated tests can be wrong or incomplete. Review and adapt them to your codebase. "
    "No code execution occurs in this app."
)
